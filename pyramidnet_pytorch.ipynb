{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49434e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "371c7d29-7f40-4519-936d-790e608c2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    outchannel_ratio = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)        \n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)        \n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "       \n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "            featuremap_size = shortcut.size()[2:4]\n",
    "        else:\n",
    "            shortcut = x\n",
    "            featuremap_size = out.size()[2:4]\n",
    "\n",
    "        batch_size = out.size()[0]\n",
    "        residual_channel = out.size()[1]\n",
    "        shortcut_channel = shortcut.size()[1]\n",
    "\n",
    "        if residual_channel != shortcut_channel:\n",
    "            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n",
    "            out += torch.cat((shortcut, padding), 1)\n",
    "        else:\n",
    "            out += shortcut \n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    outchannel_ratio = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, (planes*1), kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d((planes*1))\n",
    "        self.conv3 = nn.Conv2d((planes*1), planes * Bottleneck.outchannel_ratio, kernel_size=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(planes * Bottleneck.outchannel_ratio)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        \n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    " \n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        out = self.bn4(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "            featuremap_size = shortcut.size()[2:4]\n",
    "        else:\n",
    "            shortcut = x\n",
    "            featuremap_size = out.size()[2:4]\n",
    "\n",
    "        batch_size = out.size()[0]\n",
    "        residual_channel = out.size()[1]\n",
    "        shortcut_channel = shortcut.size()[1]\n",
    "\n",
    "        if residual_channel != shortcut_channel:\n",
    "            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n",
    "            out += torch.cat((shortcut, padding), 1)\n",
    "        else:\n",
    "            out += shortcut \n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class PyramidNet(nn.Module):\n",
    "        \n",
    "    def __init__(self, dataset, depth, alpha, num_classes, bottleneck=False):\n",
    "        super(PyramidNet, self).__init__()   \t\n",
    "        self.dataset = dataset\n",
    "        if self.dataset.startswith('cifar'):\n",
    "            self.inplanes = 16\n",
    "            if bottleneck == True:\n",
    "                n = int((depth - 2) / 9)\n",
    "                block = Bottleneck\n",
    "            else:\n",
    "                n = int((depth - 2) / 6)\n",
    "                block = BasicBlock\n",
    "\n",
    "            self.addrate = alpha / (3*n*1.0)\n",
    "\n",
    "            self.input_featuremap_dim = self.inplanes\n",
    "            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
    "\n",
    "            self.featuremap_dim = self.input_featuremap_dim \n",
    "            self.layer1 = self.pyramidal_make_layer(block, n)\n",
    "            self.layer2 = self.pyramidal_make_layer(block, n, stride=2)\n",
    "            self.layer3 = self.pyramidal_make_layer(block, n, stride=2)\n",
    "\n",
    "            self.final_featuremap_dim = self.input_featuremap_dim\n",
    "            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n",
    "            self.relu_final = nn.ReLU(inplace=True)\n",
    "            self.avgpool = nn.AvgPool2d(8)\n",
    "            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
    "\n",
    "        elif dataset == 'imagenet':\n",
    "            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n",
    "            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n",
    "\n",
    "            if layers.get(depth) is None:\n",
    "                if bottleneck == True:\n",
    "                    blocks[depth] = Bottleneck\n",
    "                    temp_cfg = int((depth-2)/12)\n",
    "                else:\n",
    "                    blocks[depth] = BasicBlock\n",
    "                    temp_cfg = int((depth-2)/8)\n",
    "\n",
    "                layers[depth]= [temp_cfg, temp_cfg, temp_cfg, temp_cfg]\n",
    "                print('=> the layer configuration for each stage is set to', layers[depth])\n",
    "\n",
    "            self.inplanes = 64            \n",
    "            self.addrate = alpha / (sum(layers[depth])*1.0)\n",
    "\n",
    "            self.input_featuremap_dim = self.inplanes\n",
    "            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "            self.featuremap_dim = self.input_featuremap_dim \n",
    "            self.layer1 = self.pyramidal_make_layer(blocks[depth], layers[depth][0])\n",
    "            self.layer2 = self.pyramidal_make_layer(blocks[depth], layers[depth][1], stride=2)\n",
    "            self.layer3 = self.pyramidal_make_layer(blocks[depth], layers[depth][2], stride=2)\n",
    "            self.layer4 = self.pyramidal_make_layer(blocks[depth], layers[depth][3], stride=2)\n",
    "\n",
    "            self.final_featuremap_dim = self.input_featuremap_dim\n",
    "            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n",
    "            self.relu_final = nn.ReLU(inplace=True)\n",
    "            self.avgpool = nn.AvgPool2d(7) \n",
    "            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def pyramidal_make_layer(self, block, block_depth, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1: # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\n",
    "            downsample = nn.AvgPool2d((2,2), stride = (2, 2), ceil_mode=True)\n",
    "\n",
    "        layers = []\n",
    "        self.featuremap_dim = self.featuremap_dim + self.addrate\n",
    "        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample))\n",
    "        for i in range(1, block_depth):\n",
    "            temp_featuremap_dim = self.featuremap_dim + self.addrate\n",
    "            layers.append(block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1))\n",
    "            self.featuremap_dim  = temp_featuremap_dim\n",
    "        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.dataset == 'cifar10' or self.dataset == 'cifar100':\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            \n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "\n",
    "            x = self.bn_final(x)\n",
    "            x = self.relu_final(x)\n",
    "            x = self.avgpool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "\n",
    "        elif self.dataset == 'imagenet':\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "\n",
    "            x = self.bn_final(x)\n",
    "            x = self.relu_final(x)\n",
    "            x = self.avgpool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb4857aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Optional, Callable\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class ImageFolder:\n",
    "    def __init__(self, root: str, final: Callable, annotations_file: Optional[str] = None, class_to_idx: Optional[dict] = None, transform: Optional[list] = None):\n",
    "        self.root = root\n",
    "        self.annotations_file = annotations_file\n",
    "        self.transform = transform\n",
    "        self.final = final\n",
    "\n",
    "        if annotations_file:\n",
    "            self.class_to_idx = class_to_idx\n",
    "            self.samples = self._load_validation_annotations()\n",
    "            self.classes = None\n",
    "        else:\n",
    "            self.classes, self.class_to_idx = self._find_classes(root)\n",
    "            self.samples = self._make_dataset()\n",
    "            \n",
    "    def get_class_to_idx(self):\n",
    "        return self.class_to_idx;\n",
    "\n",
    "    def _find_classes(self, directory: str) -> Tuple[List[str], dict]:\n",
    "        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _make_dataset(self) -> List[Tuple[str, int]]:\n",
    "        instances = []\n",
    "        for class_name in self.classes:\n",
    "            class_index = self.class_to_idx[class_name]\n",
    "            class_dir = os.path.join(self.root, class_name)\n",
    "            for root, _, fnames in sorted(os.walk(class_dir)):\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    if self._is_valid_image(path):\n",
    "                        instances.append((path, class_index))\n",
    "        return instances\n",
    "\n",
    "    def _load_validation_annotations(self) -> List[Tuple[str, int]]:\n",
    "        instances = []\n",
    "        with open(self.annotations_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            \n",
    "            image_name, class_name = parts[:2]\n",
    "            image_path = os.path.join(self.root, image_name)\n",
    "\n",
    "            class_index = self.class_to_idx[class_name]\n",
    "\n",
    "            if self._is_valid_image(image_path):\n",
    "                instances.append((image_path, class_index))\n",
    "\n",
    "        return instances\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_valid_image(path: str) -> bool:\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                img.verify()\n",
    "            return True\n",
    "        except (IOError, SyntaxError):\n",
    "            return False\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[np.ndarray, int]:\n",
    "        path, class_index = self.samples[index]\n",
    "        with Image.open(path) as img:\n",
    "            if self.transform:\n",
    "                for t in self.transform:\n",
    "                    img = t(img)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = np.array(img).transpose((2, 0, 1))\n",
    "        return self.final(img), self.final(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98670a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, dataset: ImageFolder, batch_size: int, shuffle: bool, final: Callable):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        if shuffle:\n",
    "            self.shuffle_array = np.arange(len(dataset))\n",
    "            np.random.shuffle(self.shuffle_array)\n",
    "        self.current = 0\n",
    "        self.final = final\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.current = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current >= len(self.dataset):\n",
    "            raise StopIteration\n",
    "        \n",
    "        begin = self.current\n",
    "        end = self.current + self.batch_size\n",
    "        if end > len(self.dataset):\n",
    "            end = len(self.dataset)\n",
    "        if self.shuffle == True:\n",
    "            x = [self.dataset[i][0]\n",
    "                 for i in self.shuffle_array[begin:end]]\n",
    "            y = [self.dataset[i][1]\n",
    "                 for i in self.shuffle_array[begin:end]]\n",
    "        else:\n",
    "            x = [self.dataset[i][0]\n",
    "                for i in range(begin, end)]\n",
    "            y = [self.dataset[i][1]\n",
    "                for i in range(begin, end)]\n",
    "        self.current += self.batch_size\n",
    "        return self.final(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4674ec71-c6a8-4f99-8b9d-6c350b20bb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader)):\n\u001b[1;32m---> 35\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mcuda(), \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m()\n\u001b[0;32m     36\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(out, labels)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "num_classes = 200\n",
    "depth = 18\n",
    "alpha = 48\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "transforms = [\n",
    "    lambda x: x.resize((224, 224))\n",
    "]\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    root='C:\\\\Users\\\\elect\\\\Documents\\\\SEM9\\\\Advanced Machine Learning\\\\tiny-imagenet-200\\\\train',\n",
    "    final=lambda x: torch.Tensor(x), transform=transforms)\n",
    "\n",
    "val_dataset = ImageFolder(\n",
    "    root='C:\\\\Users\\\\elect\\\\Documents\\\\SEM9\\\\Advanced Machine Learning\\\\tiny-imagenet-200\\\\val\\\\images',\n",
    "    final=lambda x: torch.Tensor(x),\n",
    "    annotations_file=\"C:/Users/elect/Documents/SEM9/Advanced Machine Learning/tiny-imagenet-200/val/val_annotations.txt\",\n",
    "    class_to_idx=train_dataset.get_class_to_idx(), transform=transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, final=lambda x: torch.stack(x))\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, final=lambda x: torch.stack(x))\n",
    "\n",
    "model = PyramidNet(dataset='imagenet', num_classes=num_classes, depth=depth, alpha=alpha)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train(True)\n",
    "for i, (images, labels) in tqdm(enumerate(train_loader)):\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    out = model(images)\n",
    "    loss = loss_fn(out, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 99:\n",
    "        pred = out.argmax(axis=-1)\n",
    "        acc = (pred == labels).mean()\n",
    "        print(f\"Loss: {loss.numpy()} | Accuracy: {acc.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a59978-cea8-4261-9e9b-055e68c35f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
